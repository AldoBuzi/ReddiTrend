apiVersion: v1
kind: Pod
metadata:
  name: spark-kafka-consumer
  namespace: kafka
spec:
    serviceAccountName: spark
    containers:
    - name: spark-consumer
      image: reddit-spark-consumer:latest
      imagePullPolicy: Never
      resources:
          requests:
            memory: "3Gi"
            cpu: "2"
          limits:
            memory: "5Gi"
            cpu: "4"
      command:
        - /opt/bitnami/spark/bin/spark-submit
        - --master
        - k8s://https://192.168.49.2:8443 #local[*] # Run Spark locally with as many worker threads as logical cores on your machine.
        - --deploy-mode
        - cluster # default is client, submitter launched driver outside of cluster
        - --conf # specify path for cache and other stuff as an absolute path
        - spark.jars.ivy=/tmp/.ivy2
        - --conf 
        - spark.kubernetes.namespace=kafka
        - --conf
        - spark.kubernetes.authenticate.driver.serviceAccountName=spark
        - --conf
        - spark.kubernetes.container.image=spark-launcher:latest
        - --conf 
        - spark.executor.instances=1
        - --conf 
        - spark.driver.memory=2g
        - --conf 
        - spark.driver.memoryOverhead=512m
        - --conf 
        - spark.executor.memory=2g
        - --conf 
        - spark.kubernetes.executor.limit.cores=1
        - --conf 
        - spark.kubernetes.driver.limit.cores=1
        - --conf 
        - spark.kubernetes.executor.request.cores=0.5
        - --conf
        - spark.kubernetes.driver.request.cores=0.5
        - --packages #required packages by spark structured streaming + kafka
        - org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.5
        - local:///opt/bitnami/spark/app/consumer.py
    restartPolicy: Never
